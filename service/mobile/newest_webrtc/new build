********************************************************webrtc代码下载，编译环境搭建，编译webrtc，可能出现的问题及解决方法********************************************************

-----------------------------------------------------------------------------------------------------------------------

下载android-sdk和android-ndk后解压到指定文件夹，开发者官网：http://developer.android.com/index.html
我是解压到/usr/local/lib下
然后指定路径
export ANDROID_SDK_ROOT=/usr/local/lib/android-sdk-linux
export ANDROID_NDK_ROOT=/usr/local/lib/android-ndk-r9
建议把上述两句话写进/etc/enviroment中，否则每次编译都要指定一次

-----------------------------------------------------------------------------------------------------------------------

编译的准备工作
首先是下载必要工具,svn和git
sudo apt-get install subversion
sudo apt-get install git

-----------------------------------------------------------------------------------------------------------------------

接下来安装Depot Tools
建议是安装在home文件夹下
svn co http://src.chromium.org/svn/trunk/tools/depot_tools
（如果安装到usr下，启动gclient需要sudo，但gclient不能sudo，这是gclient自身的问题，估计要问google才清楚，所以建议安装到home下，就不需要sudo直接就可以启动gclient）
我是解压到/home/caspar/depot_tools
然后添加depottools的主目录到PATH，具体操作步骤是
sudo vi /etc/profile
在profile文件最后面加上
PATH=$PATH:/home/caspar/depot_tools
然后要使配置生效需要重启系统
重启后命令行输入gclient测试是否安装成功

-----------------------------------------------------------------------------------------------------------------------

同样，在home下创建一个用来存放webrtc代码的文件夹
我创建的是/home/caspar/wrtc
并且将这个文件夹设置777权限，这样就不用sudo操作了
进入wrtc后执行
gclient config https://webrtc.googlecode.com/svn/trunk
然后修改.gclient，具体操作步骤是
sudo vi .gclient
在最后一行添加
target_os = ['android', 'unix']
表示在unix系统上进行android的交叉编译

-----------------------------------------------------------------------------------------------------------------------

接下来下载代码，首先在wrtc文件夹下执行
gclient sync --nohooks

-----------------------------------------------------------------------------------------------------------------------

然后安装依赖的库，操作步骤是
cd trunk
sudo ./build/install-build-deps.sh
在执行上面这句话之前建议先执行
sudo apt-get update，否则可能会有某些库因为size not match这个错误下载失败

-----------------------------------------------------------------------------------------------------------------------

接下来安装Java SE 6，
从http://www.oracle.com/technetwork/java/javase/downloads/index.html中下载
jdk-6u38-linux-x64.bin
下载后将它配置成default的java路径
cd /usr/lib/jvm && sudo /bin/sh ~/Downloads/jdk-6u38-linux-x64.bin -noregister
sudo update-alternatives --install /usr/bin/javac javac /usr/lib/jvm/jdk1.6.0_38/bin/javac 50000
sudo update-alternatives --install /usr/bin/java java /usr/lib/jvm/jdk1.6.0_38/bin/java 50000
sudo update-alternatives --install /usr/bin/javaws javaws /usr/lib/jvm/jdk1.6.0_38/bin/javaws 50000
sudo update-alternatives --install /usr/bin/javap javap /usr/lib/jvm/jdk1.6.0_38/bin/javap 50000
sudo update-alternatives --config javac
sudo update-alternatives --config java
sudo update-alternatives --config javaws
sudo update-alternatives --config javap
执行完毕后，用which java进行检验
返回结果应该是/usr/bin/java

-----------------------------------------------------------------------------------------------------------------------

配置编译环境变量
source ./build/android/envsetup.sh,应该返回
Defaulting GYP_GENERATORS to ninja.
（注意，一定要有source，执行./build/install-build-deps.sh这句话时可以没有source，但本句一定要有，否则apk和so都编译不出来，为啥还不知道，估计和cwd路径有关，实践出来就是这样）
然后退出trunk文件夹
cd ..
gclient runhooks
这句话的意思是通过gyp编译配置文件生成对应的编译脚本

-----------------------------------------------------------------------------------------------------------------------

执行完毕后，再进入trunk
cd  trunk
执行ninja -C out/Debug All开始编译

-----------------------------------------------------------------------------------------------------------------------

编译时遇到的问题
1.
BUILD FAILED
  File "/usr/lib/python2.7/subprocess.py", line 679, in __init__
    errread, errwrite)
  File "/usr/lib/python2.7/subprocess.py", line 1249, in _execute_child
    raise child_exception
OSError: [Errno 2] No such file or directory

解决方法：
sudo update-alternatives --install /usr/bin/jar jar /usr/lib/jvm/jdk1.6.0_38/bin/jar 50000

2.
android-sdks/platform-tools/aapt: error while loading shared libraries: libz.so.1: cannot open shared object file: 
No such file or directory
BUILD FAILED
/home/caspar/wrtc/trunk/webrtc/video_engine/test/android/build.xml:823: The following error occurred while executing this line:
/home/caspar/wrtc/trunk/webrtc/video_engine/test/android/build.xml:860: null returned: 127

这个错误的原因是因为我是64位机器，Android sdk是32位的，所以要安装兼容32位的库
解决方法：
sudo apt-get install ia32-libs

3.
build/build_jar.sh: Entering directory `/home/caspar/wrtc/trunk/talk'
build/build_jar.sh: line 50: /usr/lib/jvm/java-6-sun/bin/javac: No such file or directory
[164/167] LINK libjingle_peerconnection_unittest
ninja: build stopped: subcommand failed.

这个错误是因为没有配置JAVA_HOME，导致使用了默认的值java-6-sun，但我机器上没有java-6-sun，所以出错
解决方法：
关掉terminal，重开一个。在配置完之前说的那些环境变量后加上
export JAVA_HOME=/usr/lib/jvm/jdk1.6.0_38   （/usr/lib/jvm/jdk1.6.0_38是我实验时机器的路径）
重新编译即可

-----------------------------------------------------------------------------------------------------------------------

自己制作eclipse工程
编译完成后，demo工程的源代码在/home/caspar/wrtc/trunk/webrtc/video_engine/test/android下了
拷贝出来后导入eclipse（import android existed application）
但这个代码还是不能用的，需要从别的地方拷贝一些java文件，具体来说是
/home/caspar/wrtc/trunk/webrtc/modules/video_render/android/java/src/org/webrtc下的三个文件到videoengine下
/home/caspar/wrtc/trunk/webrtc/modules/video_capture/android/java/src/org/webrtc下的三个文件到videoengine下

然后在eclipse中，src文件夹下new  package,名字叫org.webrtc.voiceengine
/home/caspar/wrtc/trunk/webrtc/modules/audio_device/android/java/src/org/webrtc下的一个文件拷贝到下面

就可以通过eclipse build一个apk出来用了

-----------------------------------------------------------------------------------------------------------------------

资料：
https://code.google.com/p/chromium/wiki/AndroidBuildInstructions

-----------------------------------------------------------------------------------------------------------------------

********************************************************增加AMR编码模块，遇到的问题及解决办法********************************************************

-----------------------------------------------------------------------------------------------------------------------

首先，webrtc的框架中是有支持AMR的接口，
在trunk/webrtc/modules/audio_coding/main/source/acm_amr.cc中，
这个文件中实现的接口是给webrtc调用的，但webrtc没有做具体的编解码工作，
所以这个AMR编码的宏 WEBRTC_CODEC_AMR 是关闭的。
想要打开这个宏，修改 trunk/webrtc/engine_configurations.h 文件
在#define WEBRTC_CODEC_ILBC后面添加#define WEBRTC_CODEC_AMR即可

-----------------------------------------------------------------------------------------------------------------------

然后是增加具体的编解码，我这里用的是开源软件opencore-amr-0.1.3,
中间遇到的问题是opencore-amr-0.1.3本身编译并不难，也很快编译出.a文件供调用
但是问题是这个.a是供ubuntu使用的，而不是android，所以无法链接进webrtc
交叉编译本身也很复杂，想搞清楚要花费很多时间，最后决定采用暴力法，
自己写了一个python文件，把opencore-amr-0.1.3下所有的用的上的h和cpp都拷贝出来，
直接把这些文件加到接下来要添加的AMR编解码模块
具体步骤如下：
1.首先，建立一个文件夹，我这里是caspar。在该文件夹下面再创建三个文件夹和两个文件，分别是
  文件夹c,h,test和文件cf,hf。文件夹c存放所有的c或者cpp文件，文件夹h存放所有的h文件，cf和hf文件分别记录c或者cpp的文件名和h文件名
2.将opencore-amr-0.1.3中我们需要的文件拷贝到test下,具体来说是amrnb，oscl和opencore/codecs_v2/audio/gsm_amr/amr_nb和opencore/codecs_v2/audio/gsm_amr/common
  本次只用AMRNB，故将AMRWB的部分舍弃
3.run.py文件中讲上述的文件夹和文件路径写死了，使用者可以直接在文件中修改这些路径供自己使用

运行结果发现h文件夹下文件的个数和hf中记录的个数一致，但c文件夹下文件个数和cf中的记录差了三个，说明有重名的cpp文件
run的返回值就是其文件名，分别是div_32.cpp，l_abs.cpp，vad1.cpp

-----------------------------------------------------------------------------------------------------------------------

然后是增加AMR具体编解码的，首先是增加的AMR编解码的文件夹体系和对应的gypi脚本
在wrtc/trunk/webrtc/modules/audio_coding/codecs下增加amr（必须小写）文件夹
架构是两个文件夹，分别是include,common。include中放头文件
（根据webrtc中的架构：#include "webrtc/modules/audio_coding/codecs/amr/include/amr_interface.h"）
common中是用来存放上文中提到的三个重名文件（找出名为div_32.cpp，l_abs.cpp，vad1.cpp的所有6个cpp文件，看看这个6个文件谁在c文件夹中，将不在c文件夹中的3个cpp文件放到common文件夹中）
然后将h文件夹下所有的文件拷贝到amr/include下
然后将所有c文件中的文件复制到amr文件夹下

-----------------------------------------------------------------------------------------------------------------------

接下来完成webrtc要求我们实现的amr_interface.h（存放在amr/include）和amr_interface.c（存放在amr下）
amr_interface.h主要是实现
WebRtcAmr_CreateEnc
WebRtcAmr_CreateDec
WebRtcAmr_FreeEnc
WebRtcAmr_FreeDec
WebRtcAmr_Encode
WebRtcAmr_EncoderInit
WebRtcAmr_EncodeBitmode
WebRtcAmr_Decode
WebRtcAmr_DecodePlc
WebRtcAmr_DecoderInit
WebRtcAmr_DecodeBitmode
这些函数声明，具体细节可以查看acm_amr.h中的要求

amr_interface.c则是实现这些函数
需要特别说明的是
WebRtcAmr_EncodeBitmode
WebRtcAmr_DecoderInit
WebRtcAmr_DecodeBitmode
WebRtcAmr_DecodePlc
这四个函数因为opencore-amr-0.1.3没有对应支持的接口，所以直接返回成功了，都没有具体实现

-----------------------------------------------------------------------------------------------------------------------

然后是gypi的配置，简单的说，这是google的一个配置工具，修改后通过执行gclient runhooks生效
这个文件也要放在amr下
名字叫amr.gypi
target_name表示我们这个模块的名字，这里叫AMR（必须大写）
'type': 'static_library',
'dependencies': [
'<(webrtc_root)/common_audio/common_audio.gyp:common_audio',
],
表示和其他的gypi一样，表示生成的是静态链接库和依赖common_audio这个模块
'include_dirs': [
        'include',
      ],
'direct_dependent_settings': {
'include_dirs': [
  'include',
],
},
表示本模块的头文件所在，之前我们已经创建了include文件夹并将所有的h文件都拷贝进去了

'sources': [
        ........
        'wmf_to_ets.cpp',
        'wrapper.cpp',
      ],
sources文件表示要编码的c或者cpp或者cc文件，之前生成的hf和cf文件中已经保存了符合gypi格式的所有我们需要的opencore的h和cpp文件名，直接复制过来即可
需要注意的是因为cpp有重名文件，我们之前将重名的文件拷贝到common下了，所以在sources下添加
common/div_32.cpp
common/l_abs.cpp
common/vad1.cpp
这三句话，表示除了amr文件夹下的所有资源文件要编译，amr/common下的三个资源文件也要编译

然后在trunk/webrtc/modules/modules.gyp中增加我们新加的amr.gypi
具体操作是在'includes'中增加'audio_coding/codecs/amr/amr.gypi',
别忘了所有修改gyp配置的东东都要执行gclient runhooks生效

-----------------------------------------------------------------------------------------------------------------------

然后提前讲一下增加amr编解码模块后编译时可能会遇到的问题和解决方法

1.编译opencore的cpp文件时提示h文件没有，那就把对应的include注释，再编译
2.如果这招不行，这个文件还是有错误，那就看看opencore自己的编译脚本，看看它有没有编译这个文件，如果它的脚本中也没编译这个文件，那就把这个文件从amr.gypi的sources去掉（目前都是这个情况）
3.编译webrtc代码出错，如果是test部分的代码，那就注释掉，剩下的见招拆招都不是大问题。
4.如果想增加log信息，则采用ndk提供的__android_log_write函数，如果想使用，需要#include <android/log.h>，然后在gypi中增加
      'link_settings': {
        'ldflags': [
          '-llog'
        ],
      },
  表示在链接时，链接log库，也就是__android_log_write的具体实现所在

-----------------------------------------------------------------------------------------------------------------------

核心关键：
AMR的database
{114, "AMR", 8000, 6*160, 1, 4750},
114表示pltype，这是个协商值，双方一致即可
8000表示采样频率，采样是linear采样，采样出的数据是16 bit = 2 Byte
6*160表示6*160个sample打包一次，这里是修改过得，原来是160
1表示channel num
4750表示压缩比，原来是12200，4750是最低的了
AMR的rfc标准是160个sample就编码一次

需要注意的是，修改6*160这个值，还有一个数据结构也要修改
codec_settings_
{3, {160, 320, 960/*480*/}, 0, 1},

否则会在setcode时报错，webrtc会用codec_settings_中的数据对6*160进行判断和校验

几个概念
8000表示采样频率，采样是linear采样，采样出的数据是16 bit = 2 Byte
1s出来的采样数据就是2 * 8000 = 16K Byte
AMR标准规定的是160个sample，160*16 bit，进行一次编码压缩，4750压缩可以将320Byte的数据压缩到13Byte
解码也是如此，AMR规定一次将13Byte的数据，解码成160*16 bit的raw数据，供麦克风使用

然后webrtc的默认值是和AMR的标准一致，160个sample就压缩一次，1s 8000个sample，也就是1s要encode50次，20ms就一次
这样的话因为压缩比太高，导致净核数据只有13Byte，但报文头却要40多Byte，严重浪费

因此，webrtc也支持160*n打包，也就是160*n个sample到来后再一起打包，我们这里采用的n = 6
因此，报文长度为40+13*6，这样报文的头开销就大大降低
然而n取的过大，语音的延迟就很严重，所以综合考虑6是一个不错的选择

webrtc要求针对这种情况的处理在编解码层面完成，所以WebRtcAmr_Decode和WebRtcAmr_Encode都有一个input的len传入，可以计算出n值并处理
opencore提供的编解码接口都是符合标准，也就是160sample -> 13 Byte,13Byte -> 160 sample的接口
我要做的就是将webrtc和opencore联系起来即可，具体代码如下


int16_t WebRtcAmr_Encode(struct AMR_encinst_t_* enc_inst,int16_t* input,int16_t len,int16_t* output,int16_t mode)
{
	unsigned char* p = (unsigned char*)output;
	int16_t i = 0;
	int16_t tmp = 0;
	int16_t encodedLen = 0;
	int16_t sampleUnit = len / 160;
	for (;i < sampleUnit;i++)
	{
		tmp = Encoder_Interface_Encode(enc_inst,mode,input,p,1);
		input += 160;
		p += tmp;
		encodedLen += tmp;
	}
	return encodedLen;
}

如果在配置数据中配置成960，那webrtc传来的len就是960，input也是960个sample对应的数据，Encoder_Interface_Encode一次只编码160个sample的数据
所以循环编码，最后webrtc要求返回编码的总长度

int16_t WebRtcAmr_Decode(struct AMR_decinst_t_* dec_inst,const int16_t *encoded,int16_t len,int16_t *decoded,int16_t *speechType)
{
	unsigned char* p = (unsigned char*)encoded;
	int tmp = 0;
	int rc = 0;
	*speechType = 0;
	while(len > 0)
	{
	    tmp = Decoder_Interface_Decode(dec_inst, p, decoded, 0);
	    tmp += 1;
	    p += tmp;
	    decoded += 160;
	    len -= tmp;
	    rc += 160;
	}
	return rc;
}

解码也是如此，所要解码的数据也是13*n的这种长度，Decoder_Interface_Decode一次解码13Byte的数据，还原成160个sample的数据，和编码一样，也要循环
但Decoder_Interface_Decode返回的是解码后encoded的偏移量，所以要再加1才是长度，最后webrtc要求返回解码出多少个sample

-----------------------------------------------------------------------------------------------------------------------
